import os
import fitz  # PyMuPDF
import streamlit as st
from dotenv import load_dotenv
import chromadb
from chromadb.config import Settings
from elasticsearch import Elasticsearch
from langchain.vectorstores import Chroma, ElasticsearchStore
from langchain.embeddings import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain.retrievers import EnsembleRetriever

load_dotenv()


# ì„ë² ë”© ë° LLM ì„¤ì •
embeddings = OpenAIEmbeddings(model="text-embedding-ada-002")
llm = ChatOpenAI(model_name="gpt-4o", temperature=0.8, )

# ë²¡í„° DB ì„¤ì •
chroma_client = chromadb.HttpClient(
    host="43.202.186.183",
    port=8000,
    settings=Settings(allow_reset=True, anonymized_telemetry=False)
)
chroma_db = Chroma(
    collection_name="job_position",
    embedding_function=embeddings,
    client=chroma_client
)

es_client = Elasticsearch("http://43.202.186.183:9200", basic_auth=('elastic', 'ElastiC7276'))
es_store = ElasticsearchStore(
    es_connection=es_client,
    index_name="job_position",
    embedding=embeddings,
)

# ë¦¬íŠ¸ë¦¬ë²„ ì„¤ì •
chroma_retriever = chroma_db.as_retriever(search_kwargs={"k": 5})
es_retriever = es_store.as_retriever(search_kwargs={"k": 5})
hybrid_retriever = EnsembleRetriever(
    retrievers=[chroma_retriever, es_retriever],
    weights=[0.7, 0.3],
)

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
prompt = PromptTemplate.from_template("""
ë‹¹ì‹ ì€ ì¸ì¬ë§¤ì¹­ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ì ì´ë ¥ì„œì— ê¸°ë°˜í•˜ì—¬ ì±„ìš©ê³µê³ ë¥¼ 5ê°œ ì¶”ì²œí•´ì£¼ì„¸ìš”.

- ë°˜ë“œì‹œ ì´ë ¥ì„œì— ê¸°ë°˜í•  ê²ƒ.
- ì¶œë ¥ ì‹œ ì±„ìš©ê³µê³ ì˜ ì–‘ì‹ì„ ì‚¬ìš©í•  ê²ƒ.
- ì¶œë ¥ ì‹œ ì§€ì—­ì€ ìƒì„¸í•˜ê²Œ ì¶œë ¥ í•  ê²ƒ.
- ì±„ìš©ê³µê³  ì¶”ì²œ ì´ìœ ë¥¼ í•œì¤„ë¡œ ì„¤ëª…í•  ê²ƒ.
- ê°™ì€ ê³µê³  ë²ˆí˜¸ê°€ ì¤‘ë³µë  ê²½ìš° ë‹¨ 1ê°œë§Œ ì¶”ì²œí•  ê²ƒ.
- ì±„ìš©ê³µê³  ì „ì²´ ë‚´ìš©ì„ ê¸°ë°˜í•˜ì—¬ ë¶„ì„í•  ê²ƒ. ì œëª©ë§Œ ë³´ê³  íŒë‹¨í•˜ì§€ ë§ ê²ƒ.
- page_contentì˜ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨í•  ê²ƒ.

#ì´ë ¥ì„œ:
{question}
#ì±„ìš©ê³µê³ :
{context}

#ì¶œë ¥í˜•íƒœ
- ê¸°ì—…ëª…, ê³µê³ ëª…, [ê²½ë ¥]
- ì§ë¬´, ì§€ì—­
""")

# ì²´ì¸ êµ¬ì„±
hybrid_chain = (
    {"context": hybrid_retriever, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# Streamlit UI
st.title("ğŸ“„ ì´ë ¥ì„œ ê¸°ë°˜ ì±„ìš© ê³µê³  ì¶”ì²œ")
uploaded_file = st.file_uploader("ì´ë ¥ì„œë¥¼ PDFë¡œ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["pdf"])

if uploaded_file is not None:
    resume_text = ""
    with fitz.open(stream=uploaded_file.read(), filetype="pdf") as doc:
        for page in doc:
            resume_text += page.get_text()

    if st.button("ì¶”ì²œ ì‹œì‘ ğŸš€"):
        with st.spinner("ì±„ìš© ê³µê³  ë¶„ì„ ì¤‘..."):
            result = hybrid_chain.invoke(resume_text)
            st.subheader("ğŸ” ì¶”ì²œëœ ì±„ìš© ê³µê³ ")
            st.markdown(result)
